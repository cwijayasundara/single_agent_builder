# Agent Configuration Schema
agent:
  name: string
  description: string
  version: string

# LLM Configuration
llm:
  provider: string  # openai, anthropic, gemini, groq, etc.
  model: string     # gpt-4.1-mini, claude-3-5-sonnet-20241022, gemini-2.5-flash-preview-05-20, meta-llama/llama-4-scout-17b-16e-instruct, etc.
  temperature: float
  max_tokens: integer
  api_key_env: string  # Environment variable name for API key
  base_url: string     # Optional base URL for custom endpoints

# Prompts Configuration
prompts:
  system_prompt:
    template: string
    variables: list[string]
  user_prompt:
    template: string
    variables: list[string]
  tool_prompt:
    template: string
    variables: list[string]
  
# Tools Configuration
tools:
  built_in: list[string]  # List of built-in tool names
  custom:
    - name: string
      module_path: string
      class_name: string
      description: string
      parameters: dict

# Memory Configuration
memory:
  enabled: boolean
  provider: string  # langmem, custom
  types:
    semantic: boolean
    episodic: boolean  
    procedural: boolean
  storage:
    backend: string  # memory, postgres, redis, etc.
    connection_string: string
  settings:
    max_memory_size: integer
    retention_days: integer
    background_processing: boolean

# ReAct Configuration (simplified - no complex graph needed)
react:
  max_iterations: integer    # Maximum reasoning/acting cycles
  recursion_limit: integer   # Maximum recursion depth
  
# Optimization Configuration
optimization:
  enabled: boolean
  prompt_optimization:
    enabled: boolean
    feedback_collection: boolean
    ab_testing: boolean
    optimization_frequency: string  # daily, weekly, monthly
  performance_tracking:
    enabled: boolean
    metrics: list[string]
    
# Runtime Configuration
runtime:
  max_iterations: integer
  timeout_seconds: integer
  retry_attempts: integer
  debug_mode: boolean